{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fjo4YqDeWIup"
   },
   "source": [
    "# generative LSTM model\n",
    "\n",
    "this model uses data from poems to create it's own. by using LSTMs, the model can learn the structure of what words follow other words.\n",
    "\n",
    "\n",
    "references:\n",
    "\n",
    "[word based text generation](https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/)\n",
    "\n",
    "[letter based text generation](https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/)\n",
    "\n",
    "Tarek El-Hajjaoui\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DULa835RvWKH"
   },
   "source": [
    "Train an LSTM on the nursery rhymes below and use it to create a new nursery rhyme. The new nursery rhyme should consist of 30 lines, each of which is comprised of 20 words.\n",
    "As there is no specific quantitative metric to assess here, this portion of the writeup's analysis of results will consist of a human interpretation of the performance of the model's nursery rhyme generation.\n",
    "\n",
    "Please submit your code, a README, and the writeup. Given the multiple experiments within this assignment, your report will likely need to be ~4 pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qneDyYMMWMxf"
   },
   "source": [
    "#### connecting drive to google colab environment\n",
    "way to access files stored in google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dt8Tfbqzvl8l",
    "outputId": "14457a89-bc7a-47a1-93ed-49cbe0a25944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZiPYK7KHWoCg"
   },
   "source": [
    "## notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "g10q4pDqvWKM"
   },
   "outputs": [],
   "source": [
    "raw_poem_path = \"/content/drive/MyDrive/Colab Notebooks/poem_LSTM/data/nursery_rhymes.txt\"\n",
    "cleaned_poem_path = \"/content/drive/MyDrive/Colab Notebooks/poem_LSTM/data/poem.csv\"\n",
    "\n",
    "load_weights = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwKsErbyvWKK"
   },
   "source": [
    "## functions for: raw data -> table data\n",
    "every four lines is a new poem, two lines to the starting verses and one line to the next verse. I'll be separating the poems into table form by taking the text in each poem and matching it with the appropriate title per record in the table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU5OHWLJ4CBl"
   },
   "source": [
    "#### strip_chars\n",
    "use this to strip funky or odd characters that provice little or no meaning in the formation of words\n",
    "\n",
    "input: string to strip, optional array of characters to strip\n",
    "\n",
    "returns: stripped string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "1F2SM0p_3gEE"
   },
   "outputs": [],
   "source": [
    "def strip_chars(string_strip, char_list = ['\\n','\\\"','\\'',',',';','_','|','+','-',':','.','?','!']):\n",
    "  for char in char_list:\n",
    "    string_strip = string_strip.replace(char, '')\n",
    "  return string_strip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47_kyT9s313e"
   },
   "source": [
    "#### separate_lines_into_poems\n",
    "\n",
    "using the existing spacing in the poems txt file to build a tabular form\n",
    "\n",
    "input: file\n",
    "\n",
    "returns: text file in a csv form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "HWEZc4yZ3iJf"
   },
   "outputs": [],
   "source": [
    "def separate_lines_into_poems(lines):\n",
    "    txt_file = \"title,text\\n\"\n",
    "    \n",
    "    curr_poem = \"\"\n",
    "    poem_title = \"\"\n",
    "    \n",
    "    count_new_lines = 0\n",
    "    \n",
    "    # grabbing first title line\n",
    "    for line in lines:\n",
    "      if(line != '\\n'): \n",
    "        poem_title = strip_chars(line)\n",
    "        break\n",
    "    \n",
    "    # using spaces of four to break up poems\n",
    "    for line in lines[0:]:\n",
    "        if (count_new_lines == 4):\n",
    "\n",
    "            curr_poem = strip_chars(string_strip = curr_poem)\n",
    "\n",
    "            # curr_poem = curr_poem.replace(\"\\n\\n\", \"\\n\")\n",
    "            curr_poem = \" \".join(curr_poem.split('\\n'))\n",
    "            curr_poem = \" \".join(curr_poem.split())\n",
    "            \n",
    "            line_data = (poem_title.replace('\\n', '').replace(',','') + \",\" + curr_poem + \"\\n\").lower()\n",
    "            \n",
    "            txt_file += line_data\n",
    "            \n",
    "            curr_poem = \"\"\n",
    "            \n",
    "            poem_title = line\n",
    "        else: \n",
    "            curr_poem += line\n",
    "        \n",
    "        if (line == '\\n'):\n",
    "            count_new_lines += 1\n",
    "            \n",
    "        if (line != '\\n'):\n",
    "            count_new_lines = 0\n",
    "        \n",
    "    return txt_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td6oe_hE4Rik"
   },
   "source": [
    "#### cleaning_poem_text\n",
    "full function that cleans the poem text and writes it to the correct file\n",
    "\n",
    "input: file to read raw text from, file to write cleaned csv to\n",
    "\n",
    "returns: nothing, it writes to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ZyT8AuF43kA_"
   },
   "outputs": [],
   "source": [
    "def cleaning_poem_text(in_file, out_file):\n",
    "  # open txt file\n",
    "  with open(in_file,\"r\") as f_in:      \n",
    "    #separate the file into poems\n",
    "    poem_txt = separate_lines_into_poems(f_in.readlines())\n",
    "\n",
    "  with open(out_file, 'w') as f_out:\n",
    "    f_out.write(poem_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Htkk-7cO4ly4"
   },
   "source": [
    "## starting LSTM modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "LwDWxqNb3q4V"
   },
   "outputs": [],
   "source": [
    "cleaning_poem_text(raw_poem_path, cleaned_poem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "KwbSWDaavWKR"
   },
   "outputs": [],
   "source": [
    "# import nltk # getting standard stopwords\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U7jDP0GKhV4"
   },
   "source": [
    "#### reading poems from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "st6ZyTYSvWKS"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# creating poem titles and poem texts\n",
    "def poem_csv_reader(file_path):\n",
    "  titles = []\n",
    "  texts = []\n",
    "  with open(file_path, 'r') as csvfile:\n",
    "      reader = csv.reader(csvfile, delimiter=',')\n",
    "      next(reader)\n",
    "      for row in reader:\n",
    "          titles.append(row[0])\n",
    "          article = row[1]\n",
    "          # for word in STOPWORDS: #replacing stop words with blanks\n",
    "          #     token = ' ' + word + ' '\n",
    "          #     article = article.replace(token, ' ')\n",
    "          #     article = article.replace(' ', ' ')\n",
    "          texts.append(article)\n",
    "\n",
    "      return titles, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7ktWll8KmeM",
    "outputId": "e5d037b9-ff0f-40c1-fa2f-29b905f316f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of poem titles:  287\n",
      "number of poem texts:  287\n"
     ]
    }
   ],
   "source": [
    "poem_titles, poem_texts = poem_csv_reader(cleaned_poem_path)\n",
    "print(\"number of poem titles: \", len(poem_titles))\n",
    "print(\"number of poem texts: \", len(poem_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "bha-H4RUvWKT"
   },
   "outputs": [],
   "source": [
    "data = \" \".join(poem_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaKZY-m0dtjK"
   },
   "source": [
    "new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "QW1q_x8vPn-g"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8zAUH9o5jIV"
   },
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "LyXV_P1LhHyx"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCc-IQlOhHVK",
    "outputId": "cfd458fb-f25f-4f2b-b06d-f9aed24df6d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 2406\n"
     ]
    }
   ],
   "source": [
    "# retrieve vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25a281OshG5k",
    "outputId": "0d7358db-d77b-4165-8fd0-6d0dfac59d2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 15842\n"
     ]
    }
   ],
   "source": [
    "# encode 2 words -> 1 word\n",
    "sequences = list()\n",
    "for i in range(2, len(encoded)):\n",
    "\tsequence = encoded[i-2:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wKlqsYoghGVU",
    "outputId": "edc4377a-e619-468c-9b54-760924f63279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 3\n"
     ]
    }
   ],
   "source": [
    "# pad sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print('Max Sequence Length: %d' % max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "0zDRu8v_hFwG"
   },
   "outputs": [],
   "source": [
    "# split into input and output elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1],sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJiVmHNi5efp"
   },
   "source": [
    "## model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xahWxp68hE4B",
    "outputId": "64e5e726-51ec-46a3-e116-a60c0545aec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 2, 10)             24060     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 50)                12200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2406)              122706    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 158,966\n",
      "Trainable params: 158,966\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_length-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "yfpNWgeuhEAy"
   },
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oOaY0yDmgywb"
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "n3mYuqPmhAmg"
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "if(not load_weights):\n",
    "  model.fit(X, y, epochs=500, verbose=2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "81aUJxcdw6ly"
   },
   "outputs": [],
   "source": [
    "if(load_weights):\n",
    "  # load the network weights\n",
    "  filename = \"/content/drive/MyDrive/Colab Notebooks/poem_LSTM/weights-improvement-500-0.8179.hdf5\"\n",
    "  model.load_weights(filename)\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjoRxE_c5bE-"
   },
   "source": [
    "## sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "fT-Q1e8vtXHJ"
   },
   "outputs": [],
   "source": [
    "next_seq = \"\"\n",
    "\n",
    "import random\n",
    "def get_rand_word():\n",
    "    rand_word = ''\n",
    "    is_valid = False\n",
    "    while is_valid == False:\n",
    "      rand_word = data.split(' ')[random.randint(0, len(data.split(' ')) - 1)]\n",
    "      if rand_word != ' ' and len(rand_word) != 0:\n",
    "        is_valid = True\n",
    "    return rand_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "SN2TQZZztKqz"
   },
   "outputs": [],
   "source": [
    "def generate_seq(seed_seq='', supress_msg=True):\n",
    "    if seed_seq == '':\n",
    "      if supress_msg == False:\n",
    "        print('No sequence was chosen, a random pair of words is being \\\n",
    "      chosen as the seed text.')\n",
    "      seed_seq = get_rand_word() + \" \" + get_rand_word()\n",
    "      if supress_msg == False:\n",
    "        print(f\"Random pair chosen: {seed_seq}\")\n",
    "    # when provide the model with a pair of words\n",
    "    in_text = seed_seq\n",
    "    # set the 2nd wor of current sequence as the first for the next sequence\n",
    "    next_seq = seed_seq.split(' ')[1]\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # pre-pad sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length-1, padding='pre')\n",
    "    # predict probabilities for each word\n",
    "    predict = model.predict(encoded, verbose=0)\n",
    "    yhat=np.argmax(predict,axis=1)\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == yhat:\n",
    "        out_word = word\n",
    "        break\n",
    "    # append to input\n",
    "    in_text = out_word\n",
    "    # set the out word as the 2nd word for next_seq variable\n",
    "    next_seq += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "VF6olXirsvKi"
   },
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq_individual(model, tokenizer, max_length, seed_text, n_words):\n",
    "  in_text = seed_text\n",
    "  # generate a fixed number of words\n",
    "  for _ in range(n_words):\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # pre-pad sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n",
    "    # predict probabilities for each word\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    # yhat = np.random.choice(len(yhat),)\n",
    "    yhat = yhat.argmax(axis=-1)\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "      if index == yhat:\n",
    "        out_word = word\n",
    "        break\n",
    "\t\t# append to input\n",
    "    in_text += ' ' + out_word\n",
    "  return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZSvGz5DhCHu",
    "outputId": "4c95d297-c575-4fa4-e0ed-1c2ca92db899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kyle did our girls or as little\n",
      "Connor does z and heres\n",
      "Arman has like the lamb so mild\n",
      "pail of water the water and over\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "print(generate_seq_individual(model, tokenizer, max_length-1, 'Kyle did', 5))\n",
    "print(generate_seq_individual(model, tokenizer, max_length-1, 'Connor does', 3))\n",
    "print(generate_seq_individual(model, tokenizer, max_length-1, 'Arman has', 5))\n",
    "print(generate_seq_individual(model, tokenizer, max_length-1, 'pail of', 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Bp0LNzxsEds",
    "outputId": "e2e5ae08-e7da-488a-9e25-9eff427d8894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   and a the fish her out the a little heigho you soon with froggy then daughter the go better day for\n",
      "2   a learned say jack and wrap other miller that cow the again of you and from away of poor come water\n",
      "3   was which yourself skilful day down news when and together up you with your and says jolly a the been and\n",
      "4   so robin burden the with with in of got that lived many to love daffydowndilly must house and i cold in\n",
      "5   rowley ladle to mother so a fishes mice they horn the in up the eight was every get boy and on\n",
      "6   twenty legs but a milk all and bad a and goose the coo thomas and far cinders off as with shall\n",
      "7   dont be so had an old wrap then a s she had cat the on naughty house be for i pretty\n",
      "8   the they he got and leave rat the come then will off going or wife johnny back you in was nor\n",
      "9   or the my there so shant shall in down you at mowing and she to said reason of so the about\n",
      "10  king if two the i till read pin the my gulp in bouncing with not boy good wand play to pig\n",
      "11  peter tie asleep the queen his two away stole went she he on had said leave what nothing what i the\n",
      "12  the he he named is still the a i did nodded he pussy woman gold has on when they eat were\n",
      "13  such a my to jack are will a and back meeow to of dale away bone jane cow as can and\n",
      "14  powley you a you fol poor fly rowley begins it weather and and it ship none in as of and mouse\n",
      "15  yes and there wind or simon cat naughty he and fire it them ill the all bouncing a quoth girls she\n",
      "16  ever will dance and queen with cat high let other and bridge sun this farmer off ye your woodcock ring you\n",
      "17  did what jack blind what points and dog she a there this anon spinach bouncing dame young the rogue gave is\n",
      "18  five hector the the i i mouse full rowley king are a little a them dont notshe spread was poor it\n",
      "19  crown me a and never garden back i and old kittens gave of and woolly going and it fire says home\n",
      "20  one to as for they will was he your money stands he gave went would burden and there the a old\n",
      "21  an parson the a some have nag king had pretty crumpled two beef his slip for dickery little starts come bessy\n",
      "22  dears says away two hanged with if saturday as were all not he and ho oh bade taken bade old bright\n",
      "23  to and be tried find he his queen is the his penny when by jack will ring had gilly it and\n",
      "24  she this and dance they thrive young the betty woman go a olin of jack shoot climbed what heigh well thou\n",
      "25  a a rogue shant a little cock as have horses old crumpled up ate tell beating went the it is the\n",
      "26  he you a head in dog town there wren spain it come will i little sack his to roast man to\n",
      "27  carries house morning a of not with says a i clothes yonder babylon goosey a by shall dont into as he\n",
      "28  home she ill she carrion toll i and little what to she diller charley tried about and news and with home\n",
      "29  a gaily at a wood drake knows milk would is bit an went and spark he johnny i till pig come\n",
      "30  the were up fly fought in them the with some back tell then up he wee to king his buble my\n",
      "\n",
      "1   called she pin all and he one fly bleed joyful wedding when neer going go dine mother says a on if\n",
      "2   to children as he her hop i and tune milk said night and your then and white at come think love\n",
      "3   a rigs going says a ate nothing often and will may write made barley sake all to hop you up buble\n",
      "4   her hay sun then frog or the and the upon to swim woman notshe well go will the all burned take\n",
      "5   say clout hole either as john as her all thou by the the and lift any and little young went as\n",
      "6   it both song up full will a man them miller spoke three or his together do rat and you made it\n",
      "7   way put the i little thou wont quoth joy what man and matter in was at he do quiet they and\n",
      "8   milk bridge and i a a up the the he a mother she broom his remedy have the and silver safe\n",
      "9   a the clothes his school is that hill his it he he how ride off came wand lady to and could\n",
      "10  upon said i the had made may clean little black the lived and yellow for down them dogs his is gave\n",
      "11  the down side little cant nail little gone little i every are nest that the to look want out yonder the\n",
      "12  applepie has with you your he pulled mother cats did i one keep dig dolly if news there said and for\n",
      "13  was she carrion walls locket a cock behind but got or little rope merry for jolly she a iron her the\n",
      "14  drums frog swarm purrr i on the it not there it the and suns plum the what in such new drink\n",
      "15  shall an that he carrion must bread a be ho cake bit queen what the got his soon penny if gently\n",
      "16  wont were came over on dame he would it raised the it thief their purrr mammy ah found and the wheelbarrow\n",
      "17  water x a a old the she one the she pig jenny too eight the he pig his on care not\n",
      "18  he betty the to going pray you burden nanny high dont little to i maids the a of with why clothes\n",
      "19  dressed bit away and loved do dont try fell my good your in raven pair through three way mice was very\n",
      "20  sea get and b a old took oh of i out tune a head miller down me run fire reason fire\n",
      "21  and my a quoth the remain and burden calf mother he burden for both little a of make for i the\n",
      "22  to to so taffy she it to loved her will not wilt see says nancy was of if sung money up\n",
      "23  was this heigho the but kill with jack miller both he brought cats going and i here about mother all find\n",
      "24  the with and to tails cow not in out creep go with was heigh pigs heigh gave the had and killed\n",
      "25  the made his came little too do my and will robin the but her then is the found the it again\n",
      "26  flew neither there moon or to i the little and and the toes and over little he was you you battle\n",
      "27  back some do it heigh a and a minds h to clothes plainlooking to nobody heigh i kittens going old you\n",
      "28  wives mistress you i fiddle sing robin tail and was the and the pig carried is man and a pig a\n",
      "29  mittens there pussy and she kittens tried pounds not ill the is down cook eho can ding with old storms for\n",
      "30  making whip it does carried and to about and penny a this out at black news two of him with you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def gen_poem(trained_model, \n",
    "                      n_lines=30,\n",
    "                      n_words = 20, \n",
    "                      output_file=\"lstm_rhymes.txt\"):\n",
    "  with open(output_file, \"w\") as out_file:\n",
    "    for i in range(n_lines):\n",
    "      msg = \"{:<4}\".format(f\"{i + 1}\")\n",
    "      seed_pair = get_rand_word() + \" \" + get_rand_word()\n",
    "      curr_line = generate_seq(seed_pair)\n",
    "      for n in range(n_words):\n",
    "        curr_line += \" \" + generate_seq(next_seq)\n",
    "      msg += curr_line\n",
    "      print(msg)\n",
    "      out_file.write(msg + '\\n')\n",
    "      msg = \"\"\n",
    "      curr_line = \"\"\n",
    "    print(\"\")\n",
    "\n",
    "gen_poem(model, output_file=\"lstm_rhymes1.txt\")\n",
    "gen_poem(model, output_file=\"lstm_rhymes2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYUuDRFkM9d2"
   },
   "source": [
    "Previously I tokenized the letters an not the words. It tried to spell the words rather than using them out of a 'dictionary'. Splitting the words into a dicitonary solved this."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nursery_rhymes_LSTM.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "22e530edb2cb189d38d2622b011ee0ed40eb01e1872c49e9e897874dcd903b8e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
